{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class OurLogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"lr\": self.lr, \"num_iter\": self.num_iter}\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for parameter, value in params.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "       \n",
    "\n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "\n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "\n",
    "        # weights initialization\n",
    "        self.w = np.zeros(X.shape[1])\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.w)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X.T, (h-y)) / y.size\n",
    "            #print(gradient.shape, self.w.shape, z.shape,h.shape)\n",
    "            #gradient = (h - y) / y.size\n",
    "            self.w -= self.lr * gradient\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "\n",
    "        return self.__sigmoid(np.dot(X, self.w))\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return self.predict_prob(X) >= threshold\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # Make predictions on the input data\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        # Calculate the accuracy score\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    def accurancy(self, y_pred,y_test):\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    def precision(self, y_pred,y_test):\n",
    "        return precision_score(y_test, y_pred)\n",
    "    \n",
    "    def recall(self, y_pred,y_test):\n",
    "        return recall_score(y_test, y_pred)\n",
    "    \n",
    "    def auc(self, y_pred,y_test):\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        return fpr, tpr, roc_auc\n",
    "    \n",
    "    def plot_roc(self, fpr, tpr):\n",
    "\n",
    "        #roc_auc = auc(fpr, tpr)\n",
    "        # graficar la curva ROC\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Tasa de falsos positivos')\n",
    "        plt.ylabel('Tasa de verdaderos positivos')\n",
    "        plt.title('Curva ROC para un modelo de regresión logística')\n",
    "        plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# read the data set\n",
    "df_wine = pd.read_csv('datasets/winequality-red.csv')\n",
    "\n",
    "\"\"\"\n",
    "Data preprocessing - outlier treatment\n",
    "eliminating items from outside from of the \n",
    "1.5 * Inter Quartile Range (0.125% to 0.875% of the data)\n",
    "\"\"\"\n",
    "l_limit_perc = 0.01\n",
    "h_limit_perc = 0.99\n",
    "\n",
    "# fixed acidity\n",
    "low_limit = df_wine['fixed acidity'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['fixed acidity'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['fixed acidity'] >= low_limit) & (df_wine['fixed acidity'] <= high_limit)]\n",
    "\n",
    "# volatile acidity\n",
    "low_limit = df_wine['volatile acidity'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['volatile acidity'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['volatile acidity'] >= low_limit) & (df_wine['volatile acidity'] <= high_limit)]\n",
    "\n",
    "# citric acid\n",
    "low_limit = df_wine['citric acid'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['citric acid'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['citric acid'] >= low_limit) & (df_wine['citric acid'] <= high_limit)]\n",
    "\n",
    "# residual sugar\n",
    "low_limit = df_wine['residual sugar'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['residual sugar'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['residual sugar'] >= low_limit) & (df_wine['residual sugar'] <= high_limit)]\n",
    "\n",
    "# chlorides\n",
    "low_limit = df_wine['chlorides'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['chlorides'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['chlorides'] >= low_limit) & (df_wine['chlorides'] <= high_limit)]\n",
    "\n",
    "# free sulfur dioxide\n",
    "low_limit = df_wine['free sulfur dioxide'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['free sulfur dioxide'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['free sulfur dioxide'] >= low_limit) & (df_wine['free sulfur dioxide'] <= high_limit)]\n",
    "\n",
    "# total sulfur dioxide\n",
    "low_limit = df_wine['total sulfur dioxide'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['total sulfur dioxide'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['total sulfur dioxide'] >= low_limit) & (df_wine['total sulfur dioxide'] <= high_limit)]\n",
    "\n",
    "# density\n",
    "low_limit = df_wine['density'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['density'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['density'] >= low_limit) & (df_wine['density'] <= high_limit)]\n",
    "\n",
    "# pH\n",
    "low_limit = df_wine['pH'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['pH'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['pH'] >= low_limit) & (df_wine['pH'] <= high_limit)]\n",
    "\n",
    "# sulphates\n",
    "low_limit = df_wine['sulphates'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['sulphates'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['sulphates'] >= low_limit) & (df_wine['sulphates'] <= high_limit)]\n",
    "\n",
    "# alcohol\n",
    "low_limit = df_wine['alcohol'].quantile(l_limit_perc)\n",
    "high_limit = df_wine['alcohol'].quantile(h_limit_perc)\n",
    "df_wine = df_wine.loc[(df_wine['alcohol'] >= low_limit) & (df_wine['alcohol'] <= high_limit)]\n",
    "\n",
    "# Feature engineering \n",
    "df_wine['alcohol'] = (df_wine['alcohol']-df_wine['alcohol'].mean())/df_wine['alcohol'].std()\n",
    "df_wine['chlorides'] = (df_wine['chlorides']-df_wine['chlorides'].mean())/df_wine['chlorides'].std()\n",
    "df_wine['citric acid'] = (df_wine['citric acid']-df_wine['citric acid'].mean())/df_wine['citric acid'].std()\n",
    "df_wine['density'] = (df_wine['density']-df_wine['density'].mean())/df_wine['density'].std()\n",
    "df_wine['fixed acidity'] = (df_wine['fixed acidity']-df_wine['fixed acidity'].mean())/df_wine['fixed acidity'].std()\n",
    "df_wine['free sulfur dioxide'] = (df_wine['free sulfur dioxide']-df_wine['free sulfur dioxide'].mean())/df_wine['free sulfur dioxide'].std()\n",
    "df_wine['pH'] = (df_wine['pH']-df_wine['pH'].mean())/df_wine['pH'].std()\n",
    "df_wine['residual sugar'] = (df_wine['residual sugar']-df_wine['residual sugar'].mean())/df_wine['residual sugar'].std()\n",
    "df_wine['sulphates'] = (df_wine['sulphates']-df_wine['sulphates'].mean())/df_wine['sulphates'].std()\n",
    "df_wine['total sulfur dioxide'] = (df_wine['total sulfur dioxide']-df_wine['total sulfur dioxide'].mean())/df_wine['total sulfur dioxide'].std()\n",
    "df_wine['volatile acidity'] = (df_wine['volatile acidity']-df_wine['volatile acidity'].mean())/df_wine['volatile acidity'].std()\n",
    "\n",
    "# change the value of the output to only two values\n",
    "# 0 -> bad wine, wines with 3, 4 and 5 in quality\n",
    "# 1 -> good wine, wines with 6, 7 and 8 in queality\n",
    "df_wine.loc[df_wine['quality'] <= 5, 'quality'] = 0\n",
    "df_wine.loc[df_wine['quality'] > 5, 'quality'] = 1\n",
    "\n",
    "# Define the training and test set\n",
    "\n",
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "X0 = df_wine.loc[df_wine['quality'] == 0, features]\n",
    "Y0 = df_wine.loc[df_wine['quality'] == 0, 'quality']\n",
    "\n",
    "X1 = df_wine.loc[df_wine['quality'] == 1, features]\n",
    "Y1 = df_wine.loc[df_wine['quality'] == 1, 'quality']\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'lr': 0.001, 'num_iter': 100}\n",
      "Best accurancy score:  0.6294811320754717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.fit(X_train, y_train)\\n\\nfor test_percentage in test_percentages:\\n\\n    n_tests = int(num_rows * test_percentage)\\n    X0_test_i = X0_test.iloc[:n_tests, :]\\n    X1_test_i = X1_test.iloc[:n_tests, :]\\n    y0_test_i = y0_test.iloc[:n_tests]\\n    y1_test_i = y1_test.iloc[:n_tests]\\n\\n    X_test_i = pd.concat([X0_test_i, X1_test_i], axis= 0)\\n    y_test_i = pd.concat([y0_test_i, y1_test_i], axis= 0)\\n    y_tests.append(y_test_i)\\n\\n\\n    # predict probabilities for test set\\n    probs = model.predict_prob(X_test_i)\\n\\n    # predict classes for test set\\n    y_pred_i = model.predict(X_test_i, 0.5)\\n    y_preds.append(y_pred_i)\\n\\n    accurancies.append(model.accurancy(y_pred_i, y_test_i))\\n    precisions.append(model.precision(y_pred_i, y_test_i))\\n    recalls.append(model.recall(y_pred_i, y_test_i))\\n\\nfpr = np.array([0., 1.])\\ntpr = np.array([0., 1.])\\naucs = []\\n\\nfor i in range(len(test_percentages)):\\n    fpr_i, tpr_i, auc_i = model.auc(y_preds[i], y_tests[i])\\n    fpr = np.insert(fpr, -1, fpr_i[1])\\n    tpr = np.insert(tpr, -1, tpr_i[1])\\n    aucs.append(auc_i)\\n\\ntitle_row = ['Amount of tests', 'Accurancy', 'Precision', 'Recall', 'Auc']\\ndf_results = pd.DataFrame(columns=title_row)\\n\\nfor i, test_percentage in enumerate(test_percentages):\\n    row = [int(test_percentage*num_rows), accurancies[i], precisions[i], recalls[i], aucs[i]]\\n    df_results.loc[len(df_results)] = row\\n\\nprint(df_results)\\nmodel.plot_roc(fpr, tpr)\\n\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_percentages = [0.1, 0.25, 0.50, 0.75, 0.9, 1]\n",
    "y_tests = []\n",
    "y_preds = []\n",
    "accurancies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "X0_train, X0_test, y0_train, y0_test = train_test_split(X0, Y0, test_size=0.4, random_state=40)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, Y1, test_size=0.4, random_state=40)\n",
    "\n",
    "X_train = pd.concat([X0_train, X1_train], axis= 0)\n",
    "y_train = pd.concat([y0_train, y1_train], axis= 0)\n",
    "\n",
    "num_rows = min(X0_test.shape[0], X1_test.shape[0])\n",
    "model = OurLogisticRegression()\n",
    "param_grid = {'lr': [0.001, 0.05, 0.01],\n",
    "              'num_iter': [100, 1000, 10000]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best accurancy score: \", grid_search.best_score_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "for test_percentage in test_percentages:\n",
    "\n",
    "    n_tests = int(num_rows * test_percentage)\n",
    "    X0_test_i = X0_test.iloc[:n_tests, :]\n",
    "    X1_test_i = X1_test.iloc[:n_tests, :]\n",
    "    y0_test_i = y0_test.iloc[:n_tests]\n",
    "    y1_test_i = y1_test.iloc[:n_tests]\n",
    "\n",
    "    X_test_i = pd.concat([X0_test_i, X1_test_i], axis= 0)\n",
    "    y_test_i = pd.concat([y0_test_i, y1_test_i], axis= 0)\n",
    "    y_tests.append(y_test_i)\n",
    "\n",
    "\n",
    "    # predict probabilities for test set\n",
    "    probs = model.predict_prob(X_test_i)\n",
    "\n",
    "    # predict classes for test set\n",
    "    y_pred_i = model.predict(X_test_i, 0.5)\n",
    "    y_preds.append(y_pred_i)\n",
    "\n",
    "    accurancies.append(model.accurancy(y_pred_i, y_test_i))\n",
    "    precisions.append(model.precision(y_pred_i, y_test_i))\n",
    "    recalls.append(model.recall(y_pred_i, y_test_i))\n",
    "\n",
    "fpr = np.array([0., 1.])\n",
    "tpr = np.array([0., 1.])\n",
    "aucs = []\n",
    "\n",
    "for i in range(len(test_percentages)):\n",
    "    fpr_i, tpr_i, auc_i = model.auc(y_preds[i], y_tests[i])\n",
    "    fpr = np.insert(fpr, -1, fpr_i[1])\n",
    "    tpr = np.insert(tpr, -1, tpr_i[1])\n",
    "    aucs.append(auc_i)\n",
    "\n",
    "title_row = ['Amount of tests', 'Accurancy', 'Precision', 'Recall', 'Auc']\n",
    "df_results = pd.DataFrame(columns=title_row)\n",
    "\n",
    "for i, test_percentage in enumerate(test_percentages):\n",
    "    row = [int(test_percentage*num_rows), accurancies[i], precisions[i], recalls[i], aucs[i]]\n",
    "    df_results.loc[len(df_results)] = row\n",
    "\n",
    "print(df_results)\n",
    "model.plot_roc(fpr, tpr)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
